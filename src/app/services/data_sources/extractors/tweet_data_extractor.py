"""
ä¸»æ¨æ–‡æ•°æ®æå–å™¨

æ•´åˆæ‰€æœ‰å­æå–å™¨ï¼Œæä¾›ç»Ÿä¸€çš„æ¨æ–‡æ•°æ®æå–æ¥å£
"""

from typing import Dict, Any, List, Optional
from playwright.async_api import Page, Locator

from .base_extractor import BaseExtractor
from .tweet_content_extractor import TweetContentExtractor
from .tweet_media_extractor import TweetMediaExtractor
from .tweet_metrics_extractor import TweetMetricsExtractor
from .tweet_type_detector import TweetTypeDetector
from .special_tweet_extractor import SpecialTweetExtractor
from .rate_limit_detector import rate_limit_detector


class TweetDataExtractor(BaseExtractor):
    """
    ä¸»æ¨æ–‡æ•°æ®æå–å™¨
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œé€šè¿‡ä¾èµ–æ³¨å…¥æ•´åˆå„ä¸ªä¸“é—¨çš„æå–å™¨
    """
    
    def __init__(self, page: Page):
        super().__init__(page)
        
        # åˆå§‹åŒ–å„ä¸ªä¸“é—¨çš„æå–å™¨
        self.content_extractor = TweetContentExtractor(page)
        self.media_extractor = TweetMediaExtractor(page)
        self.metrics_extractor = TweetMetricsExtractor(page)
        self.type_detector = TweetTypeDetector(page)
        self.special_extractor = SpecialTweetExtractor(page)
    
    async def extract_all_data(self, target_tweet_id: str = None) -> Dict[str, Any]:
        """
        æå–é¡µé¢ä¸Šæ‰€æœ‰æ¨æ–‡æ•°æ®çš„ä¸»å…¥å£æ–¹æ³•
        
        Args:
            target_tweet_id: ç›®æ ‡æ¨æ–‡IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åŒ…å«æ‰€æœ‰æ¨æ–‡æ•°æ®çš„å­—å…¸
        """
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            await self._wait_for_page_load()
            
            # æŸ¥æ‰¾æ‰€æœ‰æ¨æ–‡å…ƒç´ 
            tweet_elements = await self.page.query_selector_all('[data-testid="tweet"]')
            self.logger.info(f"å‘ç° {len(tweet_elements)} ä¸ªæ¨æ–‡å…ƒç´ ")
            
            if not tweet_elements:
                # è¿›ä¸€æ­¥æ£€æŸ¥é¡µé¢çŠ¶æ€ï¼Œç¡®å®šæ¨æ–‡ä¸å­˜åœ¨çš„å…·ä½“åŸå› 
                reason = await self._analyze_no_tweet_reason()
                self.logger.info(f"æ¨æ–‡ä¸å­˜åœ¨çš„åŸå› åˆ†æ: {reason}")
                
                # æ ¹æ®åŸå› å†³å®šæ˜¯å¦éœ€è¦æ ‡è®°é”™è¯¯
                if reason in ['rate_limited', 'network_error', 'page_load_error']:
                    # è¿™äº›æ˜¯æŠ€æœ¯é—®é¢˜ï¼Œä¸åº”è¯¥æ ‡è®°ä¸ºæ¨æ–‡ä¸å­˜åœ¨
                    raise Exception(f"æŠ€æœ¯é—®é¢˜å¯¼è‡´æ— æ³•è®¿é—®æ¨æ–‡: {reason}")
                
                return self._create_empty_result(reason)
            
            # æå–æ¯ä¸ªæ¨æ–‡çš„æ•°æ®
            all_tweets = []
            for i, tweet_element in enumerate(tweet_elements):
                tweet_data = await self._extract_single_tweet(tweet_element, str(i))
                if tweet_data and tweet_data.get('text'):  # åªæ·»åŠ æœ‰å†…å®¹çš„æ¨æ–‡
                    all_tweets.append(tweet_data)
            
            # å¯¹æ¨æ–‡è¿›è¡Œåˆ†ç±»
            categorized_result = self.type_detector.categorize_tweets(all_tweets, target_tweet_id)
            
            # æå–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯
            page_context = await self._extract_page_context()
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            result = {
                **categorized_result,
                'page_context': page_context,
                'extraction_metadata': {
                    'timestamp': self._get_current_timestamp(),
                    'total_tweets_found': len(all_tweets),
                    'target_tweet_id': target_tweet_id,
                    'source': 'playwright',
                    'page_load_time': getattr(self, '_page_load_time', None)
                }
            }
            
            self.logger.info(f"æˆåŠŸæå– {len(all_tweets)} æ¡æ¨æ–‡æ•°æ®")
            return result
            
        except Exception as e:
            self.logger.error(f"Data extraction failed: {e}")
            return self._create_error_result(str(e))
    
    async def _extract_single_tweet(self, tweet_element: Locator, tweet_index: str) -> Dict[str, Any]:
        """
        æå–å•ä¸ªæ¨æ–‡çš„å®Œæ•´æ•°æ®
        
        Args:
            tweet_element: æ¨æ–‡DOMå…ƒç´ 
            tweet_index: æ¨æ–‡ç´¢å¼•
            
        Returns:
            æ¨æ–‡æ•°æ®å­—å…¸
        """
        try:
            tweet_data = {}
            
            # æå–åŸºç¡€å†…å®¹
            tweet_data["tweet_id"] = await self._extract_tweet_id(tweet_element)
            tweet_data["text"] = await self.content_extractor.extract_text_content(tweet_element)
            tweet_data["author"] = await self.content_extractor.extract_author_info(tweet_element)
            tweet_data["timestamp"] = await self.content_extractor.extract_timestamp(tweet_element)
            
            # æå–äº’åŠ¨æŒ‡æ ‡
            tweet_data["metrics"] = await self.metrics_extractor.extract_all_metrics(tweet_element)
            
            # æå–åª’ä½“å†…å®¹
            tweet_data["media"] = await self.media_extractor.extract_media_content(tweet_element)
            tweet_data["links"] = await self.media_extractor.extract_links(tweet_element)
            tweet_data["hashtags"] = await self.media_extractor.extract_hashtags(tweet_element)
            tweet_data["mentions"] = await self.media_extractor.extract_mentions(tweet_element)
            
            # ç¡®å®šæ¨æ–‡ç±»å‹å¹¶æå–ç›¸å…³å†…å®¹
            tweet_data["tweet_type"] = await self.type_detector.determine_tweet_type(tweet_element)
            tweet_data["semantic_type"] = self.type_detector.classify_tweet_type(tweet_data)
            
            # æ ¹æ®ç±»å‹æå–ç‰¹æ®Šå†…å®¹
            if tweet_data["tweet_type"] == "quote":
                tweet_data["quoted_tweet"] = await self.special_extractor.extract_quoted_tweet(tweet_element)
            elif tweet_data["tweet_type"] == "reply":
                tweet_data["reply_context"] = await self.special_extractor.extract_reply_context(tweet_element)
            elif tweet_data["tweet_type"] == "retweet":
                tweet_data["retweeted_tweet"] = await self.special_extractor.extract_retweeted_tweet(tweet_element)
            
            # æå–é™„åŠ ä¿¡æ¯
            tweet_data["language"] = await self.content_extractor.extract_language(tweet_element)
            tweet_data["location"] = await self.content_extractor.extract_location(tweet_element)
            
            return tweet_data
            
        except Exception as e:
            self.logger.error(f"Failed to extract tweet {tweet_index}: {e}")
            return {"extraction_error": str(e)}
    
    async def _extract_tweet_id(self, tweet_element: Locator) -> Optional[str]:
        """æå–æ¨æ–‡ID"""
        try:
            # æ–¹æ³•1ï¼šä»çŠ¶æ€é“¾æ¥æå–
            status_links = await tweet_element.query_selector_all('a[href*="/status/"]')
            for link in status_links:
                href = await link.get_attribute('href')
                if href:
                    import re
                    match = re.search(r'/status/(\d+)', href)
                    if match:
                        return match.group(1)
            
            # æ–¹æ³•2ï¼šä»æ—¶é—´å…ƒç´ çš„é“¾æ¥æå–
            time_links = await tweet_element.query_selector_all('time a')
            for link in time_links:
                href = await link.get_attribute('href')
                if href and '/status/' in href:
                    import re
                    match = re.search(r'/status/(\d+)', href)
                    if match:
                        return match.group(1)
            
        except Exception as e:
            self.logger.debug(f"æå–æ¨æ–‡IDå¤±è´¥: {e}")
        
        return None
    
    async def _wait_for_page_load(self, max_retries: int = 2):
        """ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆï¼Œæ”¯æŒåˆ·æ–°é‡è¯•å’Œé£æ§æ£€æµ‹"""
        import asyncio
        
        for attempt in range(max_retries + 1):
            try:
                self.logger.info(f"å¼€å§‹ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}ï¼‰ï¼Œå½“å‰URL: {self.page.url}")
                
                # é¦–å…ˆæ£€æŸ¥é¡µé¢æ ‡é¢˜ï¼Œç¡®è®¤æ²¡æœ‰è¢«é‡å®šå‘åˆ°ç™»å½•é¡µé¢
                try:
                    title = await self.page.title()
                    self.logger.info(f"é¡µé¢æ ‡é¢˜: {title}")
                    if "login" in title.lower() or "sign in" in title.lower():
                        self.logger.warning("æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®¤è¯")
                except Exception:
                    pass
                
                # ä½¿ç”¨é£æ§æ£€æµ‹å™¨å®‰å…¨åœ°ç­‰å¾…æ¨æ–‡å…ƒç´ 
                success = await rate_limit_detector.safe_wait_for_selector(
                    self.page, '[data-testid="tweet"]', timeout=5000
                )
                
                if success:
                    self.logger.info("æ‰¾åˆ°æ¨æ–‡å…ƒç´ ")
                    return  # æˆåŠŸæ‰¾åˆ°æ¨æ–‡å…ƒç´ ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                else:
                    # safe_wait_for_selectorå¤±è´¥ä½†æ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼ˆé€šå¸¸æ˜¯é£æ§ç­‰å¾…åä»å¤±è´¥ï¼‰
                    raise Exception("ç­‰å¾…æ¨æ–‡å…ƒç´ å¤±è´¥ï¼ˆå¯èƒ½è§¦å‘é£æ§ï¼‰")
                
            except Exception as e:
                self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½æ—¶å‡ºé”™ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                
                # éè¶…æ—¶é”™è¯¯ä¹Ÿå¯èƒ½éœ€è¦é£æ§å¤„ç†ï¼Œä½†è¿™é‡Œç”±safe_wait_for_selectorå·²ç»å¤„ç†äº†
                # è®°å½•å½“å‰é¡µé¢çŠ¶æ€ä»¥ä¾¿è°ƒè¯•
                try:
                    current_url = self.page.url
                    title = await self.page.title()
                    self.logger.warning(f"é¡µé¢åŠ è½½å¤±è´¥æ—¶çš„çŠ¶æ€ - URL: {current_url}, æ ‡é¢˜: {title}")
                except Exception:
                    pass
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰§è¡Œé¡µé¢åˆ·æ–°é‡è¯•
                if attempt < max_retries:
                    self.logger.info(f"ğŸ”„ æ¨¡æ‹ŸF5åˆ·æ–°é¡µé¢ï¼Œå‡†å¤‡é‡è¯•...")
                    try:
                        await self.page.reload(wait_until='domcontentloaded', timeout=10000)
                        # ç»™é¡µé¢ä¸€äº›æ—¶é—´åŠ è½½
                        await asyncio.sleep(2)
                        self.logger.info("é¡µé¢åˆ·æ–°å®Œæˆ")
                    except Exception as reload_error:
                        self.logger.error(f"é¡µé¢åˆ·æ–°å¤±è´¥: {reload_error}")
                else:
                    # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                    self.logger.error(f"é¡µé¢åŠ è½½å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    
    async def _analyze_no_tweet_reason(self) -> str:
        """åˆ†ææ¨æ–‡ä¸å­˜åœ¨çš„å…·ä½“åŸå› """
        try:
            # 1. æ£€æŸ¥é¡µé¢URLæ˜¯å¦æ­£ç¡®
            current_url = self.page.url
            if 'x.com' not in current_url and 'twitter.com' not in current_url:
                return 'redirected_away'
            
            # 2. æ£€æŸ¥é¡µé¢æ ‡é¢˜
            title = await self.page.title()
            if not title or title.strip() == '':
                return 'page_load_error'
            
            # 3. æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•æç¤º
            login_indicators = [
                '[data-testid="loginButton"]',
                '[data-testid="signupButton"]', 
                'text="Log in"',
                'text="Sign up"'
            ]
            
            for indicator in login_indicators:
                if await self.page.query_selector(indicator):
                    return 'login_required'
            
            # 4. æ£€æŸ¥æ˜¯å¦æœ‰é£æ§æç¤º
            rate_limit_indicators = [
                'text="Rate limit exceeded"',
                'text="Too many requests"',
                'text="Please try again later"',
                'text="Something went wrong"',
                '[data-testid="error"]'
            ]
            
            for indicator in rate_limit_indicators:
                if await self.page.query_selector(indicator):
                    return 'rate_limited'
            
            # 5. æ£€æŸ¥æ˜¯å¦æœ‰"æ¨æ–‡ä¸å­˜åœ¨"çš„æ˜ç¡®æç¤º
            not_found_indicators = [
                'text="This post is unavailable"',
                'text="This Tweet was deleted"',
                'text="This account doesn\'t exist"',
                'text="Sorry, that page doesn\'t exist"',
                '[data-testid="empty_state"]'
            ]
            
            for indicator in not_found_indicators:
                if await self.page.query_selector(indicator):
                    return 'tweet_not_found'
            
            # 6. æ£€æŸ¥æ˜¯å¦æœ‰ç§å¯†æˆ–å—ä¿æŠ¤çš„æ¨æ–‡æç¤º
            protected_indicators = [
                'text="These Tweets are protected"',
                'text="This account\'s Tweets are protected"',
                'text="You\'re not authorized"'
            ]
            
            for indicator in protected_indicators:
                if await self.page.query_selector(indicator):
                    return 'tweet_protected'
            
            # 7. æ£€æŸ¥æ˜¯å¦æ˜¯ä¸€ä¸ªæ­£å¸¸åŠ è½½çš„é¡µé¢ä½†å°±æ˜¯æ²¡æœ‰æ¨æ–‡
            page_content = await self.page.content()
            if len(page_content) < 1000:  # é¡µé¢å†…å®¹å¤ªå°‘ï¼Œå¯èƒ½æ˜¯åŠ è½½é—®é¢˜
                return 'page_load_error'
            
            # 8. å¦‚æœä»¥ä¸Šéƒ½ä¸æ˜¯ï¼Œå¯èƒ½æ˜¯æ¨æ–‡ç¡®å®ä¸å­˜åœ¨ï¼Œä½†é¡µé¢æ²¡æœ‰æ˜ç¡®æç¤º
            return 'tweet_possibly_not_found'
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ¨æ–‡ä¸å­˜åœ¨åŸå› æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return 'analysis_error'
    
    async def _extract_page_context(self) -> Dict[str, Any]:
        """æå–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            context = {
                'page_type': 'tweet',
                'theme': 'unknown',
                'language': 'unknown'
            }
            
            # æå–é¡µé¢è¯­è¨€
            html_element = await self.page.query_selector('html')
            if html_element:
                lang = await html_element.get_attribute('lang')
                if lang:
                    context['language'] = lang
            
            # æå–ä¸»é¢˜ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            theme_elements = await self.page.query_selector_all('[data-theme]')
            if theme_elements:
                theme = await theme_elements[0].get_attribute('data-theme')
                if theme:
                    context['theme'] = theme
            
            return context
            
        except Exception as e:
            self.logger.debug(f"æå–é¡µé¢ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {'page_type': 'tweet', 'theme': 'unknown', 'language': 'unknown'}
    
    def _create_empty_result(self, reason: str = 'No tweets found') -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'primary_tweet': None,
            'thread_tweets': [],
            'related_tweets': [],
            'page_context': {'page_type': 'tweet', 'theme': 'unknown', 'language': 'unknown'},
            'extraction_metadata': {
                'timestamp': self._get_current_timestamp(),
                'total_tweets_found': 0,
                'source': 'playwright',
                'error': reason,
                'detailed_reason': reason  # æ·»åŠ è¯¦ç»†åŸå› ä¾¿äºä¸Šå±‚åˆ¤æ–­
            }
        }
    
    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'primary_tweet': None,
            'thread_tweets': [],
            'related_tweets': [],
            'page_context': {'page_type': 'tweet', 'theme': 'unknown', 'language': 'unknown'},
            'extraction_metadata': {
                'timestamp': self._get_current_timestamp(),
                'total_tweets_found': 0,
                'source': 'playwright',
                'error': error_message
            }
        }
    
    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()